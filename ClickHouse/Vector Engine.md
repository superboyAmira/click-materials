---
tags:
  - db
  - clickhouse
  - cpu
---
Внутренняя архитектура клика основана на _векторном движке_ обработки данных. Это означает, что при выполнении запроса операции производятся не над одиночными значениями, а над _пакетами значений (векторами)_. Процессор обрабатывает сразу несколько элементов за такт с помощью SIMD-инструкций (Single Instruction – Multiple Data).

Например, вместо того чтобы суммировать числа по одному (как это сделано при скалярной обработке) , движок берет сразу диапазон (например, 256 бит, содержащих 4 значения типа 64-бит) и выполняет одну инструкцию, суммируя все 4 числа одновременно. Такой **векторный параллелизм на уровне данных** снижает затраты на обработку каждой отдельной строки и эффективно использует ресурсы CPU ([Обзор архитектуры | ClickHouse Docs](https://clickhouse.com/docs/ru/development/architecture#:~:text=ClickHouse%20%E2%80%93%20%D1%8D%D1%82%D0%BE%20%D0%B8%D1%81%D1%82%D0%B8%D0%BD%D0%BD%D0%B0%D1%8F%20%D0%BA%D0%BE%D0%BB%D0%BE%D0%BD%D0%BE%D1%87%D0%BD%D0%B0%D1%8F,%D1%81%D0%BD%D0%B8%D0%B7%D0%B8%D1%82%D1%8C%20%D1%81%D1%82%D0%BE%D0%B8%D0%BC%D0%BE%D1%81%D1%82%D1%8C%20%D1%84%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B9%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B8%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)) 

клик использует SIMD-инструкции современных процессоров (SSE4, AVX2, AVX-512 и т.д.) (это запомнаить и знгачать не нужно конечно)))), благодаря чему может за один такт выполнять сразу несколько однотипных операций над массивом данных. В классическом построчном исполнении на каждый элемент данных приходится отдельный цикл загрузки и вычисления, тогда как в клик это делается пакетно для многих элементов. **Векторизованное выполнение запросов** – один из источников высокой скорости ClickHouse ([Обзор архитектуры | ClickHouse Docs](https://clickhouse.com/docs/ru/development/architecture#:~:text=ClickHouse%20%E2%80%93%20%D1%8D%D1%82%D0%BE%20%D0%B8%D1%81%D1%82%D0%B8%D0%BD%D0%BD%D0%B0%D1%8F%20%D0%BA%D0%BE%D0%BB%D0%BE%D0%BD%D0%BE%D1%87%D0%BD%D0%B0%D1%8F,%D1%81%D0%BD%D0%B8%D0%B7%D0%B8%D1%82%D1%8C%20%D1%81%D1%82%D0%BE%D0%B8%D0%BC%D0%BE%D1%81%D1%82%D1%8C%20%D1%84%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B9%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B8%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)).

Важно отметить, что вектора – не единственный способ ускорения. Существует и метод _генерации машинного кода на лету_ (JIT) ([Обзор архитектуры | ClickHouse Docs](https://clickhouse.com/docs/ru/development/architecture#:~:text=%D0%A1%D1%83%D1%89%D0%B5%D1%81%D1%82%D0%B2%D1%83%D0%B5%D1%82%20%D0%B4%D0%B2%D0%B0%20%D1%80%D0%B0%D0%B7%D0%BD%D1%8B%D1%85%20%D0%BF%D0%BE%D0%B4%D1%85%D0%BE%D0%B4%D0%B0%20%D0%B4%D0%BB%D1%8F,%D0%98%D1%81%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D1%81%D0%BA%D0%B0%D1%8F%20%D1%81%D1%82%D0%B0%D1%82%D1%8C%D1%8F))., при котором запрос компилируется в кастомный код для более прямого выполнения. ClickHouse в основном полагается на векторизацию, имея ограниченную поддержку JIT для отдельных случаев ([Обзор архитектуры | ClickHouse Docs](https://clickhouse.com/docs/ru/development/architecture#:~:text=%D0%A1%D1%83%D1%89%D0%B5%D1%81%D1%82%D0%B2%D1%83%D0%B5%D1%82%20%D0%B4%D0%B2%D0%B0%20%D1%80%D0%B0%D0%B7%D0%BD%D1%8B%D1%85%20%D0%BF%D0%BE%D0%B4%D1%85%D0%BE%D0%B4%D0%B0%20%D0%B4%D0%BB%D1%8F,%D0%98%D1%81%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D1%81%D0%BA%D0%B0%D1%8F%20%D1%81%D1%82%D0%B0%D1%82%D1%8C%D1%8F)). комбинация этих подходов наиболее эффективна ([Обзор архитектуры | ClickHouse Docs](https://clickhouse.com/docs/ru/development/architecture#:~:text=%D0%B5%D0%B4%D0%B8%D0%BD%D0%B8%D1%86%D1%8B%20CPU%20%D0%B8%20%D0%BA%D0%BE%D0%BD%D0%B2%D0%B5%D0%B9%D0%B5%D1%80,%D0%B3%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D0%B8%20%D0%BA%D0%BE%D0%B4%D0%B0%20%D0%B2%D0%BE%20%D0%B2%D1%80%D0%B5%D0%BC%D1%8F%20%D0%B2%D1%8B%D0%BF%D0%BE%D0%BB%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F)), но клик делает ставку на векторный движок как на более простой и надёжный способ ускорения типичных аналитических задач.

#### Итог простыми словами

_Вместо того чтобы миллион раз вызывать «добавь 1 число к другому» и каждый раз оплачивать цену вызова функции, движок один раз вызывает «добавь **вот этот** блок на 8 тыс. чисел к **вот тому** блоку», затем внутри одной очень плотной, заранее оптимизированной петли прокатывает SIMD‑инструкции. Накладные расходы размазываются, а реальная работа выполняется на максимальной пропускной способности процессора и памяти._

### Если идти чуток глубже в тему:

| Принцип                                                                                                                                                                                                                                                                                                                                                                                       | Практический эффект                                                                                                                                                                                                                                                                                                                                                                                                             |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Вместо того чтобы складывать/сравнивать по одному элементу, оператор получает сразу **массив (vector)** из N однотипных значений (обычно 8 К–64 К строк). Внутри этой «порции» данные уже лежат непрерывно в памяти.                                                                                                                                                                          | • Вектор загружается в SIMD‑регистры → 4‑16 чисел обрабатываются одной машинной инструкцией.  <br>• Меньше обращений к памяти: чтение идёт большими блоками.                                                                                                                                                                                                                                                                    |
| у клика размазывается Диспетчеризация — (это накладные расходы на вызов функции/оператора (stack frame, проверка типов, виртуальный вызов и т. п.). ) Раз мы обрабатываем не одно значение, а **тысячи** за раз, на каждый элемент приходится доля overhead ≈ 1/N, что быстро стремится к нулю.                                                                                               | • CPU тратит циклы почти целиком на арифметику, а не на рамки вызовов.  <br>• JIT-компилятору/оптимизатору проще развернуть цикл и «выкинуть» лишние ветки.                                                                                                                                                                                                                                                                     |
| Разработчик движка пишет одну компактную реализацию, в которой  <br>– входной вектор проходится **плотным “for”‑циклом** без условных ветвлений;  <br>– задействуется макимально подходящяя SIMD‑инструкция<br>– развертывание ([unrolling](https://en.wikipedia.org/wiki/Loop_unrolling)) и предвыборка данных [prefetch](https://en.wikipedia.org/wiki/Cache_prefetching) настроены заранее | • Минимум branch‑mis‑predictions и cache‑miss‑ов.  <br>• Высокий IPC: однотипные [ALU](https://ru.wikipedia.org/wiki/%D0%90%D1%80%D0%B8%D1%84%D0%BC%D0%B5%D1%82%D0%B8%D0%BA%D0%BE-%D0%BB%D0%BE%D0%B3%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D1%83%D1%81%D1%82%D1%80%D0%BE%D0%B9%D1%81%D1%82%D0%B2%D0%BE)‑операции почти не простаивают.  <br>• Конкретные CPU‑фишки (AVX‑512, fused‑multiply‑add) используются по максимуму |

## Что происходит под капотом

| Шаг                                      | Что делает клик                                                                                                       | Почему это похоже на «массив в памяти»                                     |
| ---------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------- |
| 1. **Колонка → файл**                    | У каждой колонки свой отдельный поток данных (`column_name.bin` + `column_name.mrk3`).                                | Все значения подряд, без перемежения других колонок.                       |
| 2. **Блоки фиксированной гранулярности** | По умолчанию 8 192 строк формируют один «гранул»; для каждой гранулы записываются min/max‑метки (skip index).         | Получается длинный, почти непрерывный массив чисел / строк.                |
| 3. **Сжатие по колонке**                 | Сначала применяются кодеки (`LZ4`, `ZSTD`, `Delta`, …) к последовательно идущим элементам.                            | Схожие значения → отличное сжатие; разжимается пачкой сразу в L3/L2 cache. |
| 4. **MMAP + read‑ahead**                 | При чтении ClickHouse использует системный page cache и читает кусками «как есть», не раздербанивая строки.           | ОС загружает большие последовательные страницы, CPU сразу видит массив.    |
| 5. **Vectorized execution**              | В движок поступает “отрезок” колонки — массив из 2‑64 К элементов; далее AVX/AVX‑512 обрабатывают 4‑16 чисел за такт. | Память → регистр → одна SIMD‑инструкция на весь вектор.                    |
## Почему это удобно и эффективно

1. **Линейный доступ**  
    Колонка = длинный непрерывный буфер; минимальные скачки по адресу ⇒ высокая пропускная способность памяти.
2. **Кэш‑френдли**  
    В L3/L2/L1 кэш попадают целые блоки нужной колонки, а не вперемешку с чужими полями.
3. **SIMD без лишней работы**  
    Когда нужно, скажем, посчитать `sum(value)` — движок просто «мельничает» массив значений, а не извлекает их по одному из строк.
4. **Сжатие на лету**  
    Распаковка выполняется блочно (обычно 64–256 КБ); современные CPU умеют `LZ4` и `ZSTD` почти без оверхеда, так что потери минимальны.