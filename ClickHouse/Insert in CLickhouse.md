---
tags:
  - not_impl
links:
  - https://clickhouse.com/docs/en/guides/replacing-merge-tree
  - https://habr.com/ru/articles/657579/
  - https://youtu.be/XKBYYP5k_Uo?si=Dmp_ct9hLCPzSaSc
---
## Batch & Async insertion

необходимо так же сетнуть в настройках кластера поставить перемнную `max_partitions_per_insert_block` в 10000 чтобы не кидалась ошибка Code: 252. DB::Exception: Too many partitions for single INSERT block...

#  Batch 

ClickHouse достигает наилучшей производительности при загрузке данных, когда строки поступают _пакетами_, а не по одной. ВСЕ В КЛИКЕ РЕАЛИЗОВАНО ПОД ЭТО

**Почему batch-вставки быстрее:**

- **Снижение накладных расходов на каждую вставку:** При вставке данных ClickHouse обрабатывает блок (2 разных интерпретатора - Дополнтиельный на загрузку данных в РАМ), создание частей, обновление индексов, взаимодействие с диском и кипером [[Репликация и Keeper]] . Эти накладные расходы существенны при малом числе строк. Если вставлять построчно, на каждую строчку полагается overhead, что крайне неэффективно (миллионы системных вызовов, мерджей и т.д.).
- **Внутреннее представление – колонки:** ClickHouse оптимизирован для обработки _блоков_, и даже протокол вставки подразумевает, что клиент передает блок данных. Например, HTTP-интерфейс ждет CSV/TSV с множеством строк за один запрос. Клиентские драйверы тоже буферизуют данные.
- **Оптимальный размер блока:** Рекомендуется вставлять от **100 тысяч** до **миллионов строк** за раз, в зависимости от их ширины.  1000 - 10000 строк минимально разумный батч. ==Затраты на вставку 1 строки за раз = 1000000 батчу==
- **Batch вставка и слияния:** Когда вы вставляете большой блок, он записывается как одна part на диск. Мелкие вставки тоже каждая становится part. Если parts слишком много, мерджер будет сильно загружен, объединяя их. Поэтому лучше меньше частей крупнее, чем тысячи маленьких. В идеале, чтобы скорость появления новых parts не превышала скорости их слияния
![[Pasted image 20250426033815.png]]

## Async insert – асинхронные вставки

Начиная с версий около 21.x, в ClickHouse появилась возможность включить режим _асинхронных вставок_ на уровне сервера. Это означает, что клиент может отправлять INSERT, получать подтверждение быстрей, а сам ClickHouse будет некоторое время буферизовать данные (в памяти или логах) и записывать их партиями.

**Как работает async insert:**
- В настройках сервера есть опция `async_insert` и связанная `async_insert_busy_timeout`, `async_insert_max_data_size` и т.д. При включении, когда приходят многочисленные маленькие INSERTы (даже синхронные от клиентов), ClickHouse не будет сразу создавать part для каждого, а сложит данные во временное хранилище (буфер) и подождет немного, чтобы накопить более крупный блок, либо пока не истечет таймаут.
- Клиент при этом может получить _сразу OK_, как будто данные записаны (они не потеряются, даже при падении сервера, т.к. могут писаться во временный файл-журнал). Такой асинхронный режим существенно ускоряет сценарии с конкурирующими мелкими вставками, избегая большого количества маленьких частей.
- Async insert фактически реализует на уровне сервера то, что Buffer Engine делает на уровне таблицы, но более общим образом. Поэтому в документации даже говорится: _рекомендуемая альтернатива движку Buffer – включение асинхронных вставок_. Buffer engine был раньше единственным способом внутри CH буферизовать мелкие инсерты, теперь есть встроенная возможность.
- **Гарантии:** Async insert старается не потерять данные: если буфер уже записан на диск, то при сбое позже прочитается и дозапишется. Похожим путем идут классические бд – собирают транзакции и откладывают запись на диск (но клик не транзакционный, просто буферизует).
- **Клиентское использование:** Клиенту (приложению) ничего специально делать не нужно, кроме как, возможно, отключить ожидание подтверждения синхронной записи – но CH при async_insert сам будет быстро подтверждать.

==В целом, **async_insert** – более современная замена Buffer engine: он встроен, прозрачен и поддерживает реплицированные таблицы (Buffer Engine не работал с ReplicatedMergeTree, а async – работает==




==Внимание - может возникнуть противоречие. Ведь клик любит батч вставку, как тогда он может реализовывать механизм “реального времени”? ClickHouse не обрабатывает сами события в реальном времени — он возвращает аналитические запросы в реальном времени==

ClickHouse не обрабатывает миллионы отдельных вставок в секунду.

Он обрабатывает аналитические запросы в реальном времени по уже загруженным (пусть и 1–5 сек. назад) данным.

Достигается это материализованными представлениями (автоматически обновляются при поступлении новых данных в базовую таблицу). Это позволяет заранее агрегировать и преобразовывать данные, снижая нагрузку на систему при выполнении аналитических запросов в реальном времени.) , buffer view (агрегирует/отфильтровывает данные на лету при вставке)

**То есть происходит это так:**

Микро-транзакции → Буферизация/stream layer → ClickHouse (батчами) → Мгновенный SQL-запрос

**Use-case:**

· **Backend сервисы пишут события в Kafka (по одному).**

· **ClickHouse с Kafka Engine читает топик, записывает батчами в MergeTree через Materialized View.**

· **BI-дэшборд в Grafana делает SELECT count(*) GROUP BY service и получает результат за 0.2 секунды**