---
tags:
  - db
  - clickhouse
---
 не все движки не предназначены для долговременного хранения больших объемов - , но выполняют вспомогательные функции – буферизация данных, интеграция с внешними системами, организация распределенных запросов 
 
**Каждый движок имеет свое предназначение. Выбор движка – важная часть проектирования, так как от него зависят свойства таблицы: где хранятся данные, как ведут себя запросы, поддерживается ли репликация**
## Buffer

**Buffer** – специальный движок, который хранит данные таблицы временно в оперативной памяти и периодически сбрасывает их в другую (постоянную) таблицу. Проще говоря, это прослойка-буфер для сгруппированной вставки данных. Идеальное решение для Асинхронной вставки, как мы обсудили на лекции. Тоесть мы копим данные и зсылаем их в целевую таблицу ([Движок таблицы Буфер | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/special/buffer#:~:text=%D0%BF%D1%80%D0%B8%D0%BC%D0%B5%D1%87%D0%B0%D0%BD%D0%B8%D0%B5)).

**Как работает Buffer:**
![[Pasted image 20250425222153.png]]
- При вставке в таблицу с Engine=Buffer данные не сразу пишутся на диск, а помещаются в память (в буфер) ([Движок таблицы Буфер | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/special/buffer#:~:text=%D0%91%D1%83%D1%84%D0%B5%D1%80%D0%B8%D0%B7%D1%83%D0%B5%D1%82%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BB%D1%8F%20%D0%B7%D0%B0%D0%BF%D0%B8%D1%81%D0%B8%20%D0%B2,%D0%B8%20%D0%B8%D0%B7%20%D0%B4%D1%80%D1%83%D0%B3%D0%BE%D0%B9%20%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D1%8B%20%D0%BE%D0%B4%D0%BD%D0%BE%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D0%BE)). Буфер представляет собой внутреннюю временную таблицу, повторяющую структуру целевой таблицы.
- Периодически (либо при достижении определенных условий) буфер **флашится** – накопленные строки пачкой записываются в целевую таблицу на диске ([Движок таблицы Буфер | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/special/buffer#:~:text=%D0%91%D1%83%D1%84%D0%B5%D1%80%D0%B8%D0%B7%D1%83%D0%B5%D1%82%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BB%D1%8F%20%D0%B7%D0%B0%D0%BF%D0%B8%D1%81%D0%B8%20%D0%B2,%D0%B8%20%D0%B8%D0%B7%20%D0%B4%D1%80%D1%83%D0%B3%D0%BE%D0%B9%20%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D1%8B%20%D0%BE%D0%B4%D0%BD%D0%BE%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D0%BE)). Условия сброса настраиваются: например, можно задать `max_rows` или `max_bytes` – объем данных, при превышении которого произойдет запись, а также `max_time` – максимальное время удержания данных в буфере ([Движок таблицы Буфер | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/special/buffer#:~:text=,min_bytes%20%D0%B8%20max_bytes)) ([Движок таблицы Буфер | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/special/buffer#:~:text=%D0%94%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B1%D1%80%D0%B0%D1%81%D1%8B%D0%B2%D0%B0%D1%8E%D1%82%D1%81%D1%8F%20%D0%B8%D0%B7%20%D0%B1%D1%83%D1%84%D0%B5%D1%80%D0%B0%20%D0%B8,max)). Также есть `min_rows`/`min_time` – минимальные пороги, по достижении _всех_ которых данные тоже будут сброшены ([Движок таблицы Буфер | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/special/buffer#:~:text=,min_bytes%20%D0%B8%20max_bytes)).
- При **чтении** из Buffer-таблицы движок объединяет данные из оперативного буфера и данные, уже сброшенные в целевую таблицу, чтобы пользователь видел полную картину ([Движок таблицы Буфер | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/special/buffer#:~:text=%D0%91%D1%83%D1%84%D0%B5%D1%80%D0%B8%D0%B7%D1%83%D0%B5%D1%82%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BB%D1%8F%20%D0%B7%D0%B0%D0%BF%D0%B8%D1%81%D0%B8%20%D0%B2,%D0%B8%20%D0%B8%D0%B7%20%D0%B4%D1%80%D1%83%D0%B3%D0%BE%D0%B9%20%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D1%8B%20%D0%BE%D0%B4%D0%BD%D0%BE%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D0%BE)). То есть селект делает комбинированное чтение.

Ограничения Buffer - Данные хранятся в памяти – при сбое узла несброшенные данные потеряются. Также Buffer не поддерживает сложные запросы – обычно его используют только для insert. 
## Kafka

**Kafka Engine** предоставляет соединение ClickHouse с системой стриминга сообщений Apache Kafka. Таблица с движком Kafka не хранит данные сама, а представляет собой _консьюмера Kafka-топика_, позволяя ClickHouse считывать из очереди Kafka новые сообщения.

Особенности Kafka-таблицы:

- Это **только движок ввода/вывода**, данные из Kafka можно читать (SELECT) или писать (INSERT), но, как правило, такую таблицу используют вместе с _материализованным представлением_, которое читает из неё и сохраняет данные в обычную таблицу (см. далее).
- **Параметры подключения:** При создании таблицы с движком кафка нужно:
    - `kafka_broker_list` – адреса брокеров ([Kafka | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/integrations/kafka#:~:text=%D0%9E%D0%B1%D1%8F%D0%B7%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D1%8B%3A)).
    - `kafka_topic_list` – название топиков, из которых читать ([Kafka | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/integrations/kafka#:~:text=%D0%9E%D0%B1%D1%8F%D0%B7%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D1%8B%3A)).
    - `kafka_group_name` – имя группы консьюмера Kafka (для координации offset) ([Kafka | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/integrations/kafka#:~:text=,%D1%80%D0%B0%D0%B7%D0%B4%D0%B5%D0%BB%20Formats)).
    - `kafka_format` – формат сообщений ([Kafka | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/integrations/kafka#:~:text=%D0%B4%D0%BB%D1%8F%20%D0%BA%D0%B0%D0%B6%D0%B4%D0%BE%D0%B9%20%D0%B3%D1%80%D1%83%D0%BF%D0%BF%D1%8B%20%D0%BE%D1%82%D0%B4%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE,%D1%80%D0%B0%D0%B7%D0%B4%D0%B5%D0%BB%20Formats))
    Можно также задавать дополнительные опции: схему (для Protobuf к примеру), количество параллельных консьюмеров (`kafka_num_consumers`), максимум сообщений за раз (`kafka_max_block_size`), политику пропуска поврежденных сообщений (`kafka_skip_broken_messages`) и т.д. ([Kafka | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/integrations/kafka#:~:text=,%D0%B2%20%D1%81%D0%BE%D0%BE%D0%B1%D1%89%D0%B5%D0%BD%D0%B8%D1%8F%D1%85%29%20%D0%B4%D0%BB%D1%8F)) ([Kafka | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/integrations/kafka#:~:text=%D0%BE%D0%BF%D1%80%D0%BE%D1%81%D0%B0.%20%D0%9F%D0%BE%20%D1%83%D0%BC%D0%BE%D0%BB%D1%87%D0%B0%D0%BD%D0%B8%D1%8E%3A%20max_insert_block_size.%20,%D0%9F%D0%BE%20%D1%83%D0%BC%D0%BE%D0%BB%D1%87%D0%B0%D0%BD%D0%B8%D1%8E%20%D0%BF%D1%83%D1%81%D1%82%D0%BE%D0%B9)).
- **Чтение с помощью Materialized View:** Обычно на Kafka-таблицу _настраивают материализованное представление_, которое автоматически потребляет новые сообщения и вставляет их в целевую таблицу МержТрее. Сам по себе SELECT с Kafka-таблицы работает, только если включена настройка `kafka_enable_direct_select` (по умолчанию прямые SELECT отключены, чтобы случайно не “съесть” данные). Поэтому типичный паттерн:
    1. Создается таблица Engine=Kafka (консьюмер).
    2. Создается материальное представление, засылающие данные в реальную таблицу, используя SELECT из кафка-таблицы.
    Как только MV запущено, оно самостоятельно вычитывает сообщения из Kafka и кладет их в хранилище. В случае падений или остановок, при восстановлении MV продолжит с последнего зафиксированного offset (изза `kafka_group_name`).
- **Запись:** Кроме чтения, движок Kafka позволяет и писать в топик – если сделать `INSERT INTO kafka_table`, то строки будут отправлены в Kafka (требуется настроить `kafka_format` для вывода и иметь работающий коннект). Это применяется, например, для отдачи результатов SELECT в Kafka через поддержку Table Functions (можно углубиться, но это очень редкий функционал, так что знать его излишне, как по мне).

Пример создания Kafka-таблицы:

```sql
CREATE TABLE kafka_input (
    event JSON  -- структура сообщения
) ENGINE = Kafka
SETTINGS kafka_broker_list = 'kafka01:9092',
         kafka_topic_list = 'events_topic',
         kafka_group_name = 'ch_group_1',
         kafka_format = 'JSONEachRow',
         kafka_num_consumers = 1;
```

Затем создаем целевую таблицу и материализованное представление:

```sql
CREATE TABLE events AS kafka_input ENGINE = MergeTree ORDER BY tuple();
CREATE MATERIALIZED VIEW mv_consume_events TO events AS
SELECT * FROM kafka_input;
```

После этого все сообщения из Kafka-topic `events_topic` будут автоматически загружаться в таблицу `events`.

Параметры `kafka_max_block_size` и `kafka_flush_interval_ms` регулируют, с каким максимальным размером блоков и задержкой CH будет подтягивать данные ([Kafka | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/integrations/kafka#:~:text=ClickHouse.%20%D0%9F%D0%BE%20%D1%83%D0%BC%D0%BE%D0%BB%D1%87%D0%B0%D0%BD%D0%B8%D1%8E%3A%20%601%60.%20,0)) ([Kafka | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/integrations/kafka#:~:text=,%D0%BA%D0%B0%D0%B6%D0%B4%D1%8B%D0%B9%20%D0%BF%D0%BE%D1%82%D1%80%D0%B5%D0%B1%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%20%D1%81%D0%B1%D1%80%D0%B0%D1%81%D1%8B%D0%B2%D0%B0%D0%B5%D1%82%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%BD%D0%B5%D0%B7%D0%B0%D0%B2%D0%B8%D1%81%D0%B8%D0%BC%D0%BE)).

По кафке итог: Kafka-движок позволяет организовать _streaming ETL_ [etl](https://habr.com/ru/articles/248231/): Kafka собирает события, ClickHouse через материализованные представления непрерывно их выгружает в свои таблицы и сразу может агрегировать/анализировать. Это снимает необходимость в отдельном экстракторе  – роль консьюмера берёт на себя сам клик.

## File

**File Engine** – простой движок, который хранит все данные таблицы в одном _файле_ на диске (в заданном формате). Он чаще всего используется для импорта или экспорта данных, а не для постоянного хранения.


## Memory

**Memory Engine** – максимально простой движок: все данные хранятся в памяти (RAM) без какого-либо сжатия или сохранения на диск.

## Distributed – распределенная таблица (шардирование)

**Distributed Engine** – один из ключевых движков для работы в кластере. Он не хранит собственных данных, а выступает прокси для доступа к _нескольким удаленным репликам/шардам_. То есть таблица с Engine=Distributed позволяет выполнять единый запрос по данным, находящимся на разных серверах.
При создании Distributed-таблицы указываются:
    - `cluster` – имя кластера (набор настроенных в конфиге серверов).
    - `database` и `table` – имя базы и таблицы на удаленных серверах, к которым надо обращаться.
    - `sharding_key` – выражение для определения на какой шард направлять каждую запись при вставке, иожно не указывать
Пример создания (в конфигурации `config.xml` должен быть раздел `<remote_servers>` с именем кластера):

```sql
CREATE TABLE all_events
AS events  -- структура как у локальной таблицы
ENGINE = Distributed('analytics_cluster', 'analytics', 'events', rand());
```

Здесь `'analytics_cluster'` – имя кластера, настроенного в конфиге, `'analytics'` – имя БД на удаленных узлах, `'events'` – имя таблицы. `rand()` – ключ шардирования (случайно раскидывать вставки по шардам).
![[Pasted image 20250426031504.png]]
- **Чтение :** При выполнении запроса к dist-таблице он автоматически отправляет запросы параллельно на все указанные шардовые узлы, читает от них данные  и затем объединяет результат. Это происходит прозрачно для пользователя. Движок Distributed умеет эффективно распараллелить чтение – читать с удаленных узлов одновременно, и даже применять _push-down фильтрацию_: условия WHERE будут выполняться на удаленных серверах с использованием их индексов ([Движок Распределенной Таблицы | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/special/distributed#:~:text=%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%BD%D1%83%D1%8E%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D1%83%20%D0%B7%D0%B0%D0%BF%D1%80%D0%BE%D1%81%D0%BE%D0%B2%20%D0%BD%D0%B0%20%D0%BD%D0%B5%D1%81%D0%BA%D0%BE%D0%BB%D1%8C%D0%BA%D0%B8%D1%85,%D1%83%D0%B4%D0%B0%D0%BB%D0%B5%D0%BD%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%80%D0%B2%D0%B5%D1%80%D0%B0%D1%85%2C%20%D0%B5%D1%81%D0%BB%D0%B8%20%D0%BE%D0%BD%D0%B8%20%D1%81%D1%83%D1%89%D0%B5%D1%81%D1%82%D0%B2%D1%83%D1%8E%D1%82)). Таким образом, распределенный запрос почти так же эффективен, как если бы вручную запустить его на каждом сервере, и позволяет масштабировать систему горизонтально.
- **Запись (INSERT):** Если выполнить INSERT в Distributed-таблицу, данные будут распределены по шардам. По умолчанию требуется указать `sharding_key` при создании, чтобы система знала, как делить батч строк между удаленными узлами. Например, если sharding_key = UserID, строки будут разбиты по группам значений хеша UserID на разные шарды. Если ключ не указан, есть настройка `insert_distributed_one_random_shard`, позволяющая слать все на случайный шард – но обычно ключ задают. Вставки асинхронно буферизуются: клик сохранит части на локальном диске (папка `/store/название/`) и фоново отправит их на нужные узлы. Поэтому небольшие задержки в доставке вставок нормальны. Для высокой надежности лучше использовать ReplicatedMergeTree на шардах, тогда при вставке на один из реплик шардов – репликация сама разнесет на остальные.
- **Поведение SELECT на репликах:** Если на шардах есть несколько реплик (с одним именем таблицы), Distributed запросы обычно отправляются только на одну _актуальную_ реплику (актуальность чекается на стороне кипера) [[Zookeeper]], не дублируя работу
    

### НЕ ПОДДЕРЖИВАЕТ ДЖОИНЫ

**Настройка кластера:** В конфигурации сервера описывается `<remote_servers>` с именами кластеров и списком шардов и реплик. Пример (2 шарда по 2 реплики):

```xml
<remote_servers>
    <analytics_cluster>
        <shard>
            <replica>
                <host>ch-node1</host>
                <port>9000</port>
            </replica>
            <replica>
                <host>ch-node2</host>
                <port>9000</port>
            </replica>
        </shard>
        <shard>
            <replica>
                <host>ch-node3</host>
                <port>9000</port>
            </replica>
            <replica>
                <host>ch-node4</host>
                <port>9000</port>
            </replica>
        </shard>
    </analytics_cluster>
</remote_servers>
```

Теперь `ENGINE = Distributed('analytics_cluster', ...)` знает, куда ходить.

**Источник:** _Distributed-движок позволяет распределенную обработку запросов на нескольких серверах. Чтение автоматически параллелизуется, и используются индексы таблиц на удаленных серверах, если они существуют_ ([Движок Распределенной Таблицы | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/special/distributed#:~:text=%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%BD%D1%83%D1%8E%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D1%83%20%D0%B7%D0%B0%D0%BF%D1%80%D0%BE%D1%81%D0%BE%D0%B2%20%D0%BD%D0%B0%20%D0%BD%D0%B5%D1%81%D0%BA%D0%BE%D0%BB%D1%8C%D0%BA%D0%B8%D1%85,%D1%83%D0%B4%D0%B0%D0%BB%D0%B5%D0%BD%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%80%D0%B2%D0%B5%D1%80%D0%B0%D1%85%2C%20%D0%B5%D1%81%D0%BB%D0%B8%20%D0%BE%D0%BD%D0%B8%20%D1%81%D1%83%D1%89%D0%B5%D1%81%D1%82%D0%B2%D1%83%D1%8E%D1%82)) ([Движок Распределенной Таблицы | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/special/distributed#:~:text=match%20at%20L424%20%D0%BD%D0%B0%D0%B7%D1%8B%D0%B2%D0%B0%D1%82%D1%8C%D1%81%D1%8F%20%D1%83%D0%B4%D0%B0%D0%BB%D0%B5%D0%BD%D0%BD%D0%BE%D0%B9%2C,%D0%BA%D0%BE%D0%BB%D0%B8%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%BE%20%D1%80%D0%B5%D0%BF%D0%BB%D0%B8%D0%BA%20%D0%B4%D0%BB%D1%8F%20%D0%BA%D0%B0%D0%B6%D0%B4%D0%BE%D0%B3%D0%BE%20%D1%88%D0%B0%D1%80%D0%B4%D0%B0)). При вставке таблица сама распределяет данные по шардам на основе `sharding_key` (если задан) или случайно, и если таблицы на шардах реплицированы – запись идет на одну реплику и реплицируется на остальные ([Движок Распределенной Таблицы | ClickHouse Docs](https://clickhouse.com/docs/ru/engines/table-engines/special/distributed#:~:text=%D0%92%D0%BE,%D0%B5%D1%81%D0%BB%D0%B8%20%D0%B8%D0%BC%D0%B5%D0%B5%D1%82%D1%81%D1%8F%20%D1%82%D0%BE%D0%BB%D1%8C%D0%BA%D0%BE%20%D0%BE%D0%B4%D0%B8%D0%BD%20%D1%88%D0%B0%D1%80%D0%B4)).
